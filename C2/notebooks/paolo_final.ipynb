{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN12Dfrknjn4"
      },
      "outputs": [],
      "source": [
        "# Fix randomness and hide warnings\n",
        "seed = 42\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "# Fix randomness and hide warnings\n",
        "seed = 42\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "\n",
        "import logging\n",
        "\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "# Import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VaCCLVzxoKQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp /gdrive/MyDrive/ANN-HOMEWORK2/training_dataset.zip /content/training_dataset.zip\n",
        "#!unzip training_dataset.zip\n",
        "\n",
        "# Load the data\n",
        "training_data = np.load('training_data.npy')\n",
        "valid_periods = np.load('valid_periods.npy')\n",
        "categories = np.load('categories.npy')"
      ],
      "metadata": {
        "id": "B-L-jR9DnuLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split and augment\n"
      ],
      "metadata": {
        "id": "pX_36mi9rWIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Utils import split_dataset, build_sequences_optimized\n",
        "\n",
        "dataset, labels = build_sequences_optimized(training_data, valid_periods)\n",
        "train_validation_data, train_validation_labels, test_data, test_labels = split_dataset(dataset, labels)\n",
        "train_data, train_labels, validation_data, validation_labels = split_dataset(train_validation_data, train_validation_labels)\n",
        "\n",
        "train_data = train_data.reshape((train_data.shape[0], train_data.shape[1], 1))\n",
        "train_labels = train_labels.reshape((train_labels.shape[0], train_labels.shape[1], 1))\n",
        "test_data = test_data.reshape((test_data.shape[0], test_data.shape[1], 1))\n",
        "test_labels = test_labels.reshape((test_labels.shape[0], test_labels.shape[1], 1))\n",
        "test_data = test_data.reshape((test_data.shape[0], test_data.shape[1], 1))\n",
        "test_labels = test_labels.reshape((test_labels.shape[0], test_labels.shape[1], 1))\n",
        "train_data.shape"
      ],
      "metadata": {
        "id": "q8uCr7EGnuak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(train_data, train_labels, num_rounds=2):\n",
        "    num_augmentations=3\n",
        "    total_size = num_rounds * num_augmentations * len(train_data)\n",
        "\n",
        "    # Preallocate numpy arrays\n",
        "    augmented_train_data = np.empty((total_size, *train_data.shape[1:]))\n",
        "    augmented_train_labels = np.empty((total_size, *train_labels.shape[1:]))\n",
        "\n",
        "    for round in range(num_rounds):\n",
        "        print(\"Augmentation round: \", round)\n",
        "        for i in range(len(train_data)):\n",
        "            # Calculate the start index for this round and data point\n",
        "            start_idx = round * num_augmentations * len(train_data) + i * num_augmentations\n",
        "\n",
        "            # Add noise\n",
        "            noise = np.random.normal(0, 0.05, train_data[i].shape)\n",
        "            augmented_train_data[start_idx] = train_data[i] + noise\n",
        "            augmented_train_labels[start_idx] = train_labels[i]\n",
        "\n",
        "            # Add scaling\n",
        "            scaling = np.random.uniform(0.8, 1.2)\n",
        "            augmented_train_data[start_idx + 1] = train_data[i] * scaling\n",
        "            augmented_train_labels[start_idx + 1] = train_labels[i] * scaling\n",
        "\n",
        "            # Add constant value\n",
        "            constant = np.random.uniform(-0.1, 0.1)\n",
        "            augmented_train_data[start_idx + 2] = train_data[i] + constant\n",
        "            augmented_train_labels[start_idx + 2] = train_labels[i] + constant\n",
        "\n",
        "    return augmented_train_data, augmented_train_labels\n",
        "\n",
        "augmented_train_data, augmented_train_labels = augment_data(train_data, train_labels)\n",
        "# augmented_train_data, augmented_train_labels = augment_data(dataset, labels)\n",
        "augmented_train_data = augmented_train_data.reshape((augmented_train_data.shape[0], augmented_train_data.shape[1], 1))\n",
        "augmented_train_labels = augmented_train_labels.reshape((augmented_train_labels.shape[0], augmented_train_labels.shape[1], 1))\n",
        "\n",
        "# del train_data, train_labels"
      ],
      "metadata": {
        "id": "tkEqE01Cnuxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESNET 1D\n",
        "\n"
      ],
      "metadata": {
        "id": "VsX_PLMLrj5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_steps = 18\n",
        "\n",
        "def residual_block(x, filters, kernel_size):\n",
        "    \"\"\"\n",
        "    Define a basic residual block for Conv1D-based ResNet.\n",
        "    \"\"\"\n",
        "    shortcut = x\n",
        "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_resnet1D_model(input_shape, output_shape):\n",
        "    assert input_shape[0] >= output_shape[0], \"Input time steps should be >= output time steps\"\n",
        "\n",
        "    # Input layer\n",
        "    input_layer = tf.keras.layers.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    x = Conv1D(64, 3, padding='same')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # residual blocks\n",
        "    num_blocks = 5\n",
        "    for _ in range(num_blocks):\n",
        "        x = residual_block(x, 64, 3)\n",
        "\n",
        "    x = Conv1D(128, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(forecast_steps, 3, padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    output_layer = Dense(forecast_steps, activation='linear')(x)\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer, name='resnet1D_model')\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                  metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "X-z0N-O0nvAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, Reshape, Flatten, Dense\n",
        "\n",
        "input_shape = augmented_train_data.shape[1:]\n",
        "output_shape = augmented_train_labels.shape[1:]\n",
        "batch_size = 512\n",
        "epochs = 50\n",
        "\n",
        "model = build_resnet1D_model(input_shape, output_shape)\n",
        "model.summary()\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)"
      ],
      "metadata": {
        "id": "DqWl_GuFnvRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    x = augmented_train_data,\n",
        "    y = augmented_train_labels,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs,\n",
        "    validation_data=(validation_data, validation_labels),\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='loss', mode='min', min_delta=0.0003, patience=15, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='loss', mode='min', patience=8, factor=0.1, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ],
      "metadata": {
        "id": "VWusrfuZnvjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"resnet1D_5_alldata_model.h5\")"
      ],
      "metadata": {
        "id": "Z5YS1If6nv1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Utils import evaluate_model\n",
        "\n",
        "test_data_predictions = model.predict(test_data)\n",
        "evaluate_model(test_data_predictions, test_labels)"
      ],
      "metadata": {
        "id": "hktQWDkUnwGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate random samples\n",
        "evaluate_model(np.random.rand(*test_data_predictions.shape), test_labels)"
      ],
      "metadata": {
        "id": "EvpXREaUnwY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Utils import plot_predictions\n",
        "for _ in range(10):\n",
        "    idx = np.random.randint(0, len(test_data))\n",
        "    plot_predictions(test_data, test_data_predictions, test_labels,idx)\n",
        "    # Utils.plot_predictions(train_data, test_data_predictions, train_labels,idx)"
      ],
      "metadata": {
        "id": "qXEUD4ResBKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# with attention\n"
      ],
      "metadata": {
        "id": "_OMEmgAGp2Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, Flatten, Dense, Multiply, Permute, Lambda\n",
        "\n",
        "forecast_steps = 18\n",
        "\n",
        "# attention mechanism\n",
        "def self_attention(x):\n",
        "    attention_weights = Dense(units=1, activation='softmax')(x)\n",
        "    attention_output = Multiply()([x, attention_weights])\n",
        "    return attention_output\n",
        "\n",
        "def residual_block_with_attention(x, filters, kernel_size):\n",
        "    \"\"\"\n",
        "    Define a residual block with attention for Conv1D-based ResNet.\n",
        "    \"\"\"\n",
        "    shortcut = x\n",
        "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Introduce attention mechanism\n",
        "    attention = self_attention(x)\n",
        "\n",
        "    x = Add()([attention, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_resnet1D_model_with_attention(input_shape, output_shape):\n",
        "    assert input_shape[0] >= output_shape[0], \"Input time steps should be >= output time steps\"\n",
        "\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    x = Conv1D(64, 3, padding='same')(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # residual blocks with attention\n",
        "    num_blocks = 5\n",
        "    for _ in range(num_blocks):\n",
        "        x = residual_block_with_attention(x, 64, 3)\n",
        "\n",
        "    x = Conv1D(128, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv1D(forecast_steps, 3, padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    output_layer = Dense(forecast_steps, activation='linear')(x)\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
        "                  metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "input_shape = augmented_train_data.shape[1:]\n",
        "output_shape = augmented_train_labels.shape[1:]\n",
        "batch_size = 512\n",
        "epochs = 20\n",
        "\n",
        "\n",
        "# Rebuild the model with attention\n",
        "model_with_attention = build_resnet1D_model_with_attention(input_shape, output_shape)\n",
        "model_with_attention.summary()\n",
        "tf.keras.utils.plot_model(model_with_attention, expand_nested=True, show_shapes=True)\n",
        "\n",
        "# Train the model with attention\n",
        "history_attention = model_with_attention.fit(\n",
        "    x=augmented_train_data,\n",
        "    y=augmented_train_labels,\n",
        "    validation_data=(validation_data, validation_labels),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', min_delta=0.0003, patience=10, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=8, factor=0.1, min_lr=1e-5)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "JRQTDOXRp1jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Utils import evaluate_model\n",
        "\n",
        "test_data_predictions = model_with_attention.predict(test_data)\n",
        "evaluate_model(test_data_predictions, test_labels)"
      ],
      "metadata": {
        "id": "COOAin7rrDyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_attention.save(\"resnet1D_attention_model.h5\")"
      ],
      "metadata": {
        "id": "uZzD4QbDrEMV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}